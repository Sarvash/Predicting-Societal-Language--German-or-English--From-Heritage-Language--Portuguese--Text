{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d1da77-3a69-494e-aee1-44c26f0add8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 2 \tCoherence Score (C_v): 0.3151\n",
      "Number of Topics: 3 \tCoherence Score (C_v): 0.3367\n",
      "Number of Topics: 4 \tCoherence Score (C_v): 0.3596\n",
      "Number of Topics: 5 \tCoherence Score (C_v): 0.3638\n",
      "Number of Topics: 6 \tCoherence Score (C_v): 0.3850\n",
      "Number of Topics: 7 \tCoherence Score (C_v): 0.3918\n",
      "Number of Topics: 8 \tCoherence Score (C_v): 0.3916\n",
      "Number of Topics: 9 \tCoherence Score (C_v): 0.4250\n",
      "Number of Topics: 10 \tCoherence Score (C_v): 0.4227\n",
      "\n",
      "Best number of topics: 9 with Coherence Score: 0.4250\n",
      "\n",
      "Topics for the best model:\n",
      "Topic 0: 0.044*\"dia\" + 0.028*\"ano\" + 0.021*\"ir\" + 0.020*\"ter\" + 0.015*\"amigo\" + 0.014*\"casa\" + 0.013*\"pai\" + 0.013*\"vida\" + 0.012*\"bom\" + 0.011*\"eu\"\n",
      "Topic 1: 0.040*\"tecnologia\" + 0.039*\"biblioteca\" + 0.030*\"dia\" + 0.022*\"jovem\" + 0.016*\"computador\" + 0.016*\"rede\" + 0.016*\"achar\" + 0.015*\"uso\" + 0.015*\"escrever\" + 0.014*\"ir\"\n",
      "Topic 2: 0.101*\"hotel\" + 0.038*\"ter\" + 0.021*\"ficar\" + 0.016*\"gostar\" + 0.015*\"comida\" + 0.014*\"tambem\" + 0.012*\"ser\" + 0.011*\"pequeno\" + 0.011*\"haver\" + 0.011*\"b\"\n",
      "Topic 3: 0.029*\"arte\" + 0.026*\"ano\" + 0.025*\"guia\" + 0.020*\"gostar\" + 0.017*\"turístico\" + 0.016*\"posto\" + 0.015*\"trabalho\" + 0.013*\"trabalhar\" + 0.013*\"museu\" + 0.013*\"falar\"\n",
      "Topic 4: 0.042*\"mundo\" + 0.029*\"problema\" + 0.023*\"realidade\" + 0.021*\"virtual\" + 0.020*\"futuro\" + 0.015*\"haver\" + 0.013*\"mandar\" + 0.012*\"ser\" + 0.012*\"uso\" + 0.012*\"jogo\"\n",
      "Topic 5: 0.041*\"livro\" + 0.019*\"ajudar\" + 0.016*\"gostar\" + 0.015*\"animal\" + 0.015*\"ano\" + 0.013*\"ler\" + 0.012*\"portugal\" + 0.011*\"vida\" + 0.010*\"festival\" + 0.009*\"música\"\n",
      "Topic 6: 0.042*\"fotografia\" + 0.020*\"natureza\" + 0.019*\"foto\" + 0.018*\"trabalhar\" + 0.015*\"parque\" + 0.015*\"ajudar\" + 0.013*\"tema\" + 0.012*\"criança\" + 0.011*\"verão\" + 0.011*\"bom\"\n",
      "Topic 7: 0.039*\"tablet\" + 0.029*\"dia\" + 0.025*\"tambem\" + 0.013*\"escola\" + 0.013*\"tablets\" + 0.012*\"amigo\" + 0.012*\"livro\" + 0.012*\"gostar\" + 0.011*\"blogue\" + 0.011*\"falar\"\n",
      "Topic 8: 0.029*\"ajudar\" + 0.018*\"achar\" + 0.016*\"ano\" + 0.015*\"escrever\" + 0.015*\"mundo\" + 0.015*\"trabalho\" + 0.014*\"projeto\" + 0.012*\"ser\" + 0.011*\"haver\" + 0.011*\"gostar\"\n",
      "CSV updated with topic assignments.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_md\")\n",
    "\n",
    "directories = [] # This variable should contain the subcorpus directories.\n",
    "\n",
    "passes = 10  # for LDA\n",
    "\n",
    "csv_path = \"all-features-structures-hl2c.csv\"\n",
    "\n",
    "def read_text_files_from_directories(dir_list):\n",
    "    texts = []\n",
    "    filenames = []\n",
    "    for d in dir_list:\n",
    "        txt_files = glob.glob(os.path.join(d, \"*.txt\"))\n",
    "        for fpath in txt_files:\n",
    "            with open(fpath, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                content = file.read()\n",
    "                texts.append(content)\n",
    "                filenames.append(os.path.basename(fpath))\n",
    "    return texts, filenames\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    processed_docs = []\n",
    "    for doc in nlp.pipe(texts, disable=[\"ner\", \"parser\"]):\n",
    "        tokens = [\n",
    "            token.lemma_.lower() \n",
    "            for token in doc \n",
    "            if not token.is_stop\n",
    "            and token.is_alpha\n",
    "        ]\n",
    "        processed_docs.append(tokens)\n",
    "    return processed_docs\n",
    "\n",
    "\n",
    "raw_texts, filenames = read_text_files_from_directories(directories)\n",
    "processed_docs = preprocess_text(raw_texts)\n",
    "dictionary = Dictionary(processed_docs)\n",
    "# Filter out words that occur in less than 5 documents or more than 50% of documents\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "# Convert documents into a bag-of-words format\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Range of number of topics\n",
    "topic_nums = range(2, 11)  # from 2 to 10 topics\n",
    "coherence_scores = []\n",
    "\n",
    "# Evaluate coherence for different numbers of topics\n",
    "for k in topic_nums:\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, passes=passes, random_state=42)\n",
    "\n",
    "    # Compute Coherence Score using C_v coherence\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append((k, coherence_score))\n",
    "\n",
    "    print(f\"Number of Topics: {k} \\tCoherence Score (C_v): {coherence_score:.4f}\")\n",
    "\n",
    "# Find the best number of topics\n",
    "best_k, best_score = max(coherence_scores, key=lambda x: x[1])\n",
    "print(f\"\\nBest number of topics: {best_k} with Coherence Score: {best_score:.4f}\")\n",
    "\n",
    "# Retrain the model with the best number of topics\n",
    "best_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=best_k, passes=passes, random_state=42)\n",
    "\n",
    "# Print the most representative words for each topic in the best model\n",
    "print(\"\\nTopics for the best model:\")\n",
    "for idx, topic in best_model.print_topics(num_topics=best_k, num_words=10):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "# Assign topics to each document\n",
    "doc_topics = []\n",
    "for doc_bow in corpus:\n",
    "    # get_document_topics returns a list of (topic_id, probability)\n",
    "    topic_distribution = best_model.get_document_topics(doc_bow, minimum_probability=0.0)\n",
    "    # Find the topic with the highest probability\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "    doc_topics.append(dominant_topic)\n",
    "\n",
    "# Now we have a list `doc_topics` with the topic assigned to each document\n",
    "# and a list `filenames` that matches the index of doc_topics.\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "# Create a dictionary mapping from filename to topic\n",
    "filename_to_topic = {fn: t for fn, t in zip(filenames, doc_topics)}\n",
    "\n",
    "# Map each row's Text_Title to its topic\n",
    "df['Topic'] = df['Text_Title'].map(filename_to_topic)\n",
    "\n",
    "col_order = list(df.columns)\n",
    "prof_index = col_order.index('Proficiency')\n",
    "# Remove Topic from the end\n",
    "col_order.remove('Topic')\n",
    "# Insert after Proficiency\n",
    "col_order.insert(prof_index + 1, 'Topic')\n",
    "df = df[col_order]\n",
    "\n",
    "# Save the modified dataframe\n",
    "df.to_csv(\"features-structures-topics-hl2c.csv\", index=False)\n",
    "print(\"CSV updated with topic assignments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ca4726-210b-4dd0-b3fe-ea1c7c5e1356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Title</th>\n",
       "      <th>Country</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Cohesive Complexity Feature: Difficult Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Easy Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes Additive Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes All Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes Causal Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes Concessive Connectives per Token</th>\n",
       "      <th>...</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - forma irregular de particípio per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - particípios irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - particípios regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do indicativo - verbos irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do indicativo - verbos regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito mais-que-perfeito simples do indicativo per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito perfeito composto do conjuntivo per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito perfeito simples do indicativo - verbos irregulares per verb tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND_20B1AA_0121.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND_20B1AA_0810.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND_20B1AA_0867.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND_20B1AA_4710.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND_20B1AA_5817.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>UK_22C1AE_82X7.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>UK_22C1AE_8423.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>UK_22C1AE_8605.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>UK_22C1AE_8714.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>UK_22C1AE_9706.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 659 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Text_Title Country Proficiency  Topic  \\\n",
       "0    AND_20B1AA_0121.txt     AND          B1    NaN   \n",
       "1    AND_20B1AA_0810.txt     AND          B1    NaN   \n",
       "2    AND_20B1AA_0867.txt     AND          B1    NaN   \n",
       "3    AND_20B1AA_4710.txt     AND          B1    NaN   \n",
       "4    AND_20B1AA_5817.txt     AND          B1    NaN   \n",
       "..                   ...     ...         ...    ...   \n",
       "521   UK_22C1AE_82X7.txt      UK          C1    5.0   \n",
       "522   UK_22C1AE_8423.txt      UK          C1    4.0   \n",
       "523   UK_22C1AE_8605.txt      UK          C1    8.0   \n",
       "524   UK_22C1AE_8714.txt      UK          C1    5.0   \n",
       "525   UK_22C1AE_9706.txt      UK          C1    5.0   \n",
       "\n",
       "     Cohesive Complexity Feature: Difficult Connectives per Token  \\\n",
       "0                                             0.015385              \n",
       "1                                             0.034483              \n",
       "2                                             0.000000              \n",
       "3                                             0.016260              \n",
       "4                                             0.006623              \n",
       "..                                                 ...              \n",
       "521                                           0.005556              \n",
       "522                                           0.030120              \n",
       "523                                           0.017045              \n",
       "524                                           0.018405              \n",
       "525                                           0.033708              \n",
       "\n",
       "     Cohesive Complexity Feature: Easy Connectives per Token  \\\n",
       "0                                             0.069231         \n",
       "1                                             0.080460         \n",
       "2                                             0.041667         \n",
       "3                                             0.056911         \n",
       "4                                             0.086093         \n",
       "..                                                 ...         \n",
       "521                                           0.094444         \n",
       "522                                           0.096386         \n",
       "523                                           0.085227         \n",
       "524                                           0.073620         \n",
       "525                                           0.078652         \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes Additive Connectives per Token  \\\n",
       "0                                             0.015385                    \n",
       "1                                             0.034483                    \n",
       "2                                             0.031250                    \n",
       "3                                             0.016260                    \n",
       "4                                             0.033113                    \n",
       "..                                                 ...                    \n",
       "521                                           0.061111                    \n",
       "522                                           0.036145                    \n",
       "523                                           0.022727                    \n",
       "524                                           0.030675                    \n",
       "525                                           0.016854                    \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes All Connectives per Token  \\\n",
       "0                                             0.092308               \n",
       "1                                             0.126437               \n",
       "2                                             0.083333               \n",
       "3                                             0.081301               \n",
       "4                                             0.125828               \n",
       "..                                                 ...               \n",
       "521                                           0.133333               \n",
       "522                                           0.108434               \n",
       "523                                           0.107955               \n",
       "524                                           0.079755               \n",
       "525                                           0.112360               \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes Causal Connectives per Token  \\\n",
       "0                                             0.023077                  \n",
       "1                                             0.022989                  \n",
       "2                                             0.010417                  \n",
       "3                                             0.016260                  \n",
       "4                                             0.006623                  \n",
       "..                                                 ...                  \n",
       "521                                           0.005556                  \n",
       "522                                           0.018072                  \n",
       "523                                           0.011364                  \n",
       "524                                           0.006135                  \n",
       "525                                           0.022472                  \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes Concessive Connectives per Token  \\\n",
       "0                                             0.000000                      \n",
       "1                                             0.000000                      \n",
       "2                                             0.000000                      \n",
       "3                                             0.000000                      \n",
       "4                                             0.000000                      \n",
       "..                                                 ...                      \n",
       "521                                           0.000000                      \n",
       "522                                           0.006024                      \n",
       "523                                           0.000000                      \n",
       "524                                           0.000000                      \n",
       "525                                           0.000000                      \n",
       "\n",
       "     ...  \\\n",
       "0    ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "..   ...   \n",
       "521  ...   \n",
       "522  ...   \n",
       "523  ...   \n",
       "524  ...   \n",
       "525  ...   \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - forma irregular de particípio per verb tokens  \\\n",
       "0                                                  0.0                                            \n",
       "1                                                  0.0                                            \n",
       "2                                                  0.0                                            \n",
       "3                                                  0.0                                            \n",
       "4                                                  0.0                                            \n",
       "..                                                 ...                                            \n",
       "521                                                0.0                                            \n",
       "522                                                0.0                                            \n",
       "523                                                0.0                                            \n",
       "524                                                0.0                                            \n",
       "525                                                0.0                                            \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - particípios irregulares per verb tokens  \\\n",
       "0                                             0.000000                                      \n",
       "1                                             0.000000                                      \n",
       "2                                             0.000000                                      \n",
       "3                                             0.000000                                      \n",
       "4                                             0.000000                                      \n",
       "..                                                 ...                                      \n",
       "521                                           0.048780                                      \n",
       "522                                           0.057143                                      \n",
       "523                                           0.000000                                      \n",
       "524                                           0.000000                                      \n",
       "525                                           0.000000                                      \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - particípios regulares per verb tokens  \\\n",
       "0                                             0.000000                                    \n",
       "1                                             0.000000                                    \n",
       "2                                             0.115385                                    \n",
       "3                                             0.080000                                    \n",
       "4                                             0.000000                                    \n",
       "..                                                 ...                                    \n",
       "521                                           0.024390                                    \n",
       "522                                           0.142857                                    \n",
       "523                                           0.083333                                    \n",
       "524                                           0.083333                                    \n",
       "525                                           0.166667                                    \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos irregulares per verb tokens  \\\n",
       "0                                             0.000000                                                 \n",
       "1                                             0.000000                                                 \n",
       "2                                             0.000000                                                 \n",
       "3                                             0.000000                                                 \n",
       "4                                             0.000000                                                 \n",
       "..                                                 ...                                                 \n",
       "521                                           0.024390                                                 \n",
       "522                                           0.000000                                                 \n",
       "523                                           0.027778                                                 \n",
       "524                                           0.000000                                                 \n",
       "525                                           0.000000                                                 \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos regulares per verb tokens  \\\n",
       "0                                             0.000000                                               \n",
       "1                                             0.000000                                               \n",
       "2                                             0.000000                                               \n",
       "3                                             0.000000                                               \n",
       "4                                             0.000000                                               \n",
       "..                                                 ...                                               \n",
       "521                                           0.024390                                               \n",
       "522                                           0.028571                                               \n",
       "523                                           0.000000                                               \n",
       "524                                           0.000000                                               \n",
       "525                                           0.000000                                               \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do indicativo - verbos irregulares per verb tokens  \\\n",
       "0                                                  0.0                                                 \n",
       "1                                                  0.0                                                 \n",
       "2                                                  0.0                                                 \n",
       "3                                                  0.0                                                 \n",
       "4                                                  0.0                                                 \n",
       "..                                                 ...                                                 \n",
       "521                                                0.0                                                 \n",
       "522                                                0.0                                                 \n",
       "523                                                0.0                                                 \n",
       "524                                                0.0                                                 \n",
       "525                                                0.0                                                 \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do indicativo - verbos regulares per verb tokens  \\\n",
       "0                                             0.076923                                               \n",
       "1                                             0.000000                                               \n",
       "2                                             0.038462                                               \n",
       "3                                             0.040000                                               \n",
       "4                                             0.000000                                               \n",
       "..                                                 ...                                               \n",
       "521                                           0.024390                                               \n",
       "522                                           0.000000                                               \n",
       "523                                           0.000000                                               \n",
       "524                                           0.000000                                               \n",
       "525                                           0.000000                                               \n",
       "\n",
       "     Grammatical Complexity: Pretérito mais-que-perfeito simples do indicativo per verb tokens  \\\n",
       "0                                                  0.0                                           \n",
       "1                                                  0.0                                           \n",
       "2                                                  0.0                                           \n",
       "3                                                  0.0                                           \n",
       "4                                                  0.0                                           \n",
       "..                                                 ...                                           \n",
       "521                                                0.0                                           \n",
       "522                                                0.0                                           \n",
       "523                                                0.0                                           \n",
       "524                                                0.0                                           \n",
       "525                                                0.0                                           \n",
       "\n",
       "     Grammatical Complexity: Pretérito perfeito composto do conjuntivo per verb tokens  \\\n",
       "0                                                  0.0                                   \n",
       "1                                                  0.0                                   \n",
       "2                                                  0.0                                   \n",
       "3                                                  0.0                                   \n",
       "4                                                  0.0                                   \n",
       "..                                                 ...                                   \n",
       "521                                                0.0                                   \n",
       "522                                                0.0                                   \n",
       "523                                                0.0                                   \n",
       "524                                                0.0                                   \n",
       "525                                                0.0                                   \n",
       "\n",
       "     Grammatical Complexity: Pretérito perfeito simples do indicativo - verbos irregulares per verb tokens  \n",
       "0                                              0.00000                                                      \n",
       "1                                              0.00000                                                      \n",
       "2                                              0.00000                                                      \n",
       "3                                              0.08000                                                      \n",
       "4                                              0.00000                                                      \n",
       "..                                                 ...                                                      \n",
       "521                                            0.02439                                                      \n",
       "522                                            0.00000                                                      \n",
       "523                                            0.00000                                                      \n",
       "524                                            0.00000                                                      \n",
       "525                                            0.00000                                                      \n",
       "\n",
       "[526 rows x 659 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe59352-339c-4e48-9cbb-3d37b72379fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_descriptions = {\n",
    "    0: \"Personal Life and Relationships\",\n",
    "    1: \"Technology, Libraries, and Youth\",\n",
    "    2: \"Travel and Accommodation\",\n",
    "    3: \"Art, Tourism, and Cultural Activities\",\n",
    "    4: \"Global and Virtual Realities\",\n",
    "    5: \"Books, Culture, and Leisure\",\n",
    "    6: \"Nature and Outdoor Photography\",\n",
    "    7: \"Tablets, Education, and Everyday Tech\",\n",
    "    8: \"Work, Projects, and Global Engagement\"\n",
    "}\n",
    "\n",
    "# Replace numeric topics with descriptive labels\n",
    "df[\"Topic\"] = df[\"Topic\"].map(topic_descriptions)\n",
    "\n",
    "# General topic classification based on descriptive topic names\n",
    "general_topic_mapping = {\n",
    "    \"Personal Life and Relationships\": \"Personal, Cultural, and Recreational Life\",\n",
    "    \"Books, Culture, and Leisure\": \"Personal, Cultural, and Recreational Life\",\n",
    "    \"Art, Tourism, and Cultural Activities\": \"Personal, Cultural, and Recreational Life\",\n",
    "    \"Travel and Accommodation\": \"Personal, Cultural, and Recreational Life\",\n",
    "    \"Nature and Outdoor Photography\": \"Personal, Cultural, and Recreational Life\",\n",
    "    \"Tablets, Education, and Everyday Tech\": \"Technology and Digital Environments\",\n",
    "    \"Technology, Libraries, and Youth\": \"Technology and Digital Environments\",\n",
    "    \"Global and Virtual Realities\": \"Technology and Digital Environments\",\n",
    "    \"Work, Projects, and Global Engagement\": \"Work and Professional Engagement\"\n",
    "}\n",
    "\n",
    "# Map the general topics based on the updated \"Topic\" column\n",
    "df[\"General Topic\"] = df[\"Topic\"].map(general_topic_mapping)\n",
    "\n",
    "# Reorder columns so that \"General Topic\" comes right after \"Topic\"\n",
    "col_order = list(df.columns)\n",
    "topic_index = col_order.index('Topic')\n",
    "# Remove General Topic from the end if it's there\n",
    "col_order.remove('General Topic')\n",
    "# Insert it right after Topic\n",
    "col_order.insert(topic_index + 1, 'General Topic')\n",
    "df = df[col_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ba4a6b-eabc-4551-8ed7-7d947ad12e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Title</th>\n",
       "      <th>Country</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>Topic</th>\n",
       "      <th>General Topic</th>\n",
       "      <th>Cohesive Complexity Feature: Difficult Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Easy Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes Additive Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes All Connectives per Token</th>\n",
       "      <th>Cohesive Complexity Feature: Mendes Causal Connectives per Token</th>\n",
       "      <th>...</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - forma irregular de particípio per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - particípios irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Particípio passado - particípios regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do indicativo - verbos irregulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito imperfeito do indicativo - verbos regulares per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito mais-que-perfeito simples do indicativo per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito perfeito composto do conjuntivo per verb tokens</th>\n",
       "      <th>Grammatical Complexity: Pretérito perfeito simples do indicativo - verbos irregulares per verb tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AND_20B1AA_0121.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AND_20B1AA_0810.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND_20B1AA_0867.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND_20B1AA_4710.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND_20B1AA_5817.txt</td>\n",
       "      <td>AND</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>UK_22C1AE_82X7.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>Books, Culture, and Leisure</td>\n",
       "      <td>Personal, Cultural, and Recreational Life</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>UK_22C1AE_8423.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>Global and Virtual Realities</td>\n",
       "      <td>Technology and Digital Environments</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>UK_22C1AE_8605.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>Work, Projects, and Global Engagement</td>\n",
       "      <td>Work and Professional Engagement</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>UK_22C1AE_8714.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>Books, Culture, and Leisure</td>\n",
       "      <td>Personal, Cultural, and Recreational Life</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>UK_22C1AE_9706.txt</td>\n",
       "      <td>UK</td>\n",
       "      <td>C1</td>\n",
       "      <td>Books, Culture, and Leisure</td>\n",
       "      <td>Personal, Cultural, and Recreational Life</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 660 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Text_Title Country Proficiency  \\\n",
       "0    AND_20B1AA_0121.txt     AND          B1   \n",
       "1    AND_20B1AA_0810.txt     AND          B1   \n",
       "2    AND_20B1AA_0867.txt     AND          B1   \n",
       "3    AND_20B1AA_4710.txt     AND          B1   \n",
       "4    AND_20B1AA_5817.txt     AND          B1   \n",
       "..                   ...     ...         ...   \n",
       "521   UK_22C1AE_82X7.txt      UK          C1   \n",
       "522   UK_22C1AE_8423.txt      UK          C1   \n",
       "523   UK_22C1AE_8605.txt      UK          C1   \n",
       "524   UK_22C1AE_8714.txt      UK          C1   \n",
       "525   UK_22C1AE_9706.txt      UK          C1   \n",
       "\n",
       "                                     Topic  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "..                                     ...   \n",
       "521            Books, Culture, and Leisure   \n",
       "522           Global and Virtual Realities   \n",
       "523  Work, Projects, and Global Engagement   \n",
       "524            Books, Culture, and Leisure   \n",
       "525            Books, Culture, and Leisure   \n",
       "\n",
       "                                 General Topic  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "..                                         ...   \n",
       "521  Personal, Cultural, and Recreational Life   \n",
       "522        Technology and Digital Environments   \n",
       "523           Work and Professional Engagement   \n",
       "524  Personal, Cultural, and Recreational Life   \n",
       "525  Personal, Cultural, and Recreational Life   \n",
       "\n",
       "     Cohesive Complexity Feature: Difficult Connectives per Token  \\\n",
       "0                                             0.015385              \n",
       "1                                             0.034483              \n",
       "2                                             0.000000              \n",
       "3                                             0.016260              \n",
       "4                                             0.006623              \n",
       "..                                                 ...              \n",
       "521                                           0.005556              \n",
       "522                                           0.030120              \n",
       "523                                           0.017045              \n",
       "524                                           0.018405              \n",
       "525                                           0.033708              \n",
       "\n",
       "     Cohesive Complexity Feature: Easy Connectives per Token  \\\n",
       "0                                             0.069231         \n",
       "1                                             0.080460         \n",
       "2                                             0.041667         \n",
       "3                                             0.056911         \n",
       "4                                             0.086093         \n",
       "..                                                 ...         \n",
       "521                                           0.094444         \n",
       "522                                           0.096386         \n",
       "523                                           0.085227         \n",
       "524                                           0.073620         \n",
       "525                                           0.078652         \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes Additive Connectives per Token  \\\n",
       "0                                             0.015385                    \n",
       "1                                             0.034483                    \n",
       "2                                             0.031250                    \n",
       "3                                             0.016260                    \n",
       "4                                             0.033113                    \n",
       "..                                                 ...                    \n",
       "521                                           0.061111                    \n",
       "522                                           0.036145                    \n",
       "523                                           0.022727                    \n",
       "524                                           0.030675                    \n",
       "525                                           0.016854                    \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes All Connectives per Token  \\\n",
       "0                                             0.092308               \n",
       "1                                             0.126437               \n",
       "2                                             0.083333               \n",
       "3                                             0.081301               \n",
       "4                                             0.125828               \n",
       "..                                                 ...               \n",
       "521                                           0.133333               \n",
       "522                                           0.108434               \n",
       "523                                           0.107955               \n",
       "524                                           0.079755               \n",
       "525                                           0.112360               \n",
       "\n",
       "     Cohesive Complexity Feature: Mendes Causal Connectives per Token  ...  \\\n",
       "0                                             0.023077                 ...   \n",
       "1                                             0.022989                 ...   \n",
       "2                                             0.010417                 ...   \n",
       "3                                             0.016260                 ...   \n",
       "4                                             0.006623                 ...   \n",
       "..                                                 ...                 ...   \n",
       "521                                           0.005556                 ...   \n",
       "522                                           0.018072                 ...   \n",
       "523                                           0.011364                 ...   \n",
       "524                                           0.006135                 ...   \n",
       "525                                           0.022472                 ...   \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - forma irregular de particípio per verb tokens  \\\n",
       "0                                                  0.0                                            \n",
       "1                                                  0.0                                            \n",
       "2                                                  0.0                                            \n",
       "3                                                  0.0                                            \n",
       "4                                                  0.0                                            \n",
       "..                                                 ...                                            \n",
       "521                                                0.0                                            \n",
       "522                                                0.0                                            \n",
       "523                                                0.0                                            \n",
       "524                                                0.0                                            \n",
       "525                                                0.0                                            \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - particípios irregulares per verb tokens  \\\n",
       "0                                             0.000000                                      \n",
       "1                                             0.000000                                      \n",
       "2                                             0.000000                                      \n",
       "3                                             0.000000                                      \n",
       "4                                             0.000000                                      \n",
       "..                                                 ...                                      \n",
       "521                                           0.048780                                      \n",
       "522                                           0.057143                                      \n",
       "523                                           0.000000                                      \n",
       "524                                           0.000000                                      \n",
       "525                                           0.000000                                      \n",
       "\n",
       "     Grammatical Complexity: Particípio passado - particípios regulares per verb tokens  \\\n",
       "0                                             0.000000                                    \n",
       "1                                             0.000000                                    \n",
       "2                                             0.115385                                    \n",
       "3                                             0.080000                                    \n",
       "4                                             0.000000                                    \n",
       "..                                                 ...                                    \n",
       "521                                           0.024390                                    \n",
       "522                                           0.142857                                    \n",
       "523                                           0.083333                                    \n",
       "524                                           0.083333                                    \n",
       "525                                           0.166667                                    \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos irregulares per verb tokens  \\\n",
       "0                                             0.000000                                                 \n",
       "1                                             0.000000                                                 \n",
       "2                                             0.000000                                                 \n",
       "3                                             0.000000                                                 \n",
       "4                                             0.000000                                                 \n",
       "..                                                 ...                                                 \n",
       "521                                           0.024390                                                 \n",
       "522                                           0.000000                                                 \n",
       "523                                           0.027778                                                 \n",
       "524                                           0.000000                                                 \n",
       "525                                           0.000000                                                 \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do conjuntivo - verbos regulares per verb tokens  \\\n",
       "0                                             0.000000                                               \n",
       "1                                             0.000000                                               \n",
       "2                                             0.000000                                               \n",
       "3                                             0.000000                                               \n",
       "4                                             0.000000                                               \n",
       "..                                                 ...                                               \n",
       "521                                           0.024390                                               \n",
       "522                                           0.028571                                               \n",
       "523                                           0.000000                                               \n",
       "524                                           0.000000                                               \n",
       "525                                           0.000000                                               \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do indicativo - verbos irregulares per verb tokens  \\\n",
       "0                                                  0.0                                                 \n",
       "1                                                  0.0                                                 \n",
       "2                                                  0.0                                                 \n",
       "3                                                  0.0                                                 \n",
       "4                                                  0.0                                                 \n",
       "..                                                 ...                                                 \n",
       "521                                                0.0                                                 \n",
       "522                                                0.0                                                 \n",
       "523                                                0.0                                                 \n",
       "524                                                0.0                                                 \n",
       "525                                                0.0                                                 \n",
       "\n",
       "     Grammatical Complexity: Pretérito imperfeito do indicativo - verbos regulares per verb tokens  \\\n",
       "0                                             0.076923                                               \n",
       "1                                             0.000000                                               \n",
       "2                                             0.038462                                               \n",
       "3                                             0.040000                                               \n",
       "4                                             0.000000                                               \n",
       "..                                                 ...                                               \n",
       "521                                           0.024390                                               \n",
       "522                                           0.000000                                               \n",
       "523                                           0.000000                                               \n",
       "524                                           0.000000                                               \n",
       "525                                           0.000000                                               \n",
       "\n",
       "     Grammatical Complexity: Pretérito mais-que-perfeito simples do indicativo per verb tokens  \\\n",
       "0                                                  0.0                                           \n",
       "1                                                  0.0                                           \n",
       "2                                                  0.0                                           \n",
       "3                                                  0.0                                           \n",
       "4                                                  0.0                                           \n",
       "..                                                 ...                                           \n",
       "521                                                0.0                                           \n",
       "522                                                0.0                                           \n",
       "523                                                0.0                                           \n",
       "524                                                0.0                                           \n",
       "525                                                0.0                                           \n",
       "\n",
       "     Grammatical Complexity: Pretérito perfeito composto do conjuntivo per verb tokens  \\\n",
       "0                                                  0.0                                   \n",
       "1                                                  0.0                                   \n",
       "2                                                  0.0                                   \n",
       "3                                                  0.0                                   \n",
       "4                                                  0.0                                   \n",
       "..                                                 ...                                   \n",
       "521                                                0.0                                   \n",
       "522                                                0.0                                   \n",
       "523                                                0.0                                   \n",
       "524                                                0.0                                   \n",
       "525                                                0.0                                   \n",
       "\n",
       "     Grammatical Complexity: Pretérito perfeito simples do indicativo - verbos irregulares per verb tokens  \n",
       "0                                              0.00000                                                      \n",
       "1                                              0.00000                                                      \n",
       "2                                              0.00000                                                      \n",
       "3                                              0.08000                                                      \n",
       "4                                              0.00000                                                      \n",
       "..                                                 ...                                                      \n",
       "521                                            0.02439                                                      \n",
       "522                                            0.00000                                                      \n",
       "523                                            0.00000                                                      \n",
       "524                                            0.00000                                                      \n",
       "525                                            0.00000                                                      \n",
       "\n",
       "[526 rows x 660 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545b032a-d909-4904-9c47-d662d0ab69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"features-structures-topics-hl2c.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1415b61-9ca8-404b-be71-f1411b51ff18",
   "metadata": {},
   "source": [
    "# Calculating Number of Texts and Average Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ef2c64-c218-4fad-8aa6-3ca5bcf503f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of texts processed: 472\n",
      "Number of texts excluded: 7\n",
      "\n",
      "Number of texts by directory:\n",
      "DE_B1_TRANSCRIBED: 102 texts\n",
      "DE_B2_TRANSCRIBED: 100 texts\n",
      "DE_C1_TRANSCRIBED: 101 texts\n",
      "UK_B1_TRANSCRIBED: 90 texts\n",
      "UK_B2_TRANSCRIBED: 37 texts\n",
      "UK_C1_TRANSCRIBED: 42 texts\n",
      "\n",
      "Average Word Count: 162.03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Directories to read text files from\n",
    "directories = []\n",
    "\n",
    "# These files didn't contain any text.\n",
    "files_to_exclude = {\n",
    "    \"DE_20B1BZ_4833.txt\",\n",
    "    \"DE_21B2AE_1MX1.txt\",\n",
    "    \"DE_21C1AE_5146.txt\",\n",
    "    \"DE_22B1BA_FVJV.txt\",\n",
    "    \"UK_21B1AZ_3994.txt\",\n",
    "    \"UK_22B1BE_2259.txt\",\n",
    "    \"UK_22B1BE_8732.txt\"\n",
    "}\n",
    "\n",
    "def read_text_files_from_directories(dir_list, exclude_files):\n",
    "    texts = []\n",
    "    total_files = 0\n",
    "    file_counts_by_dir = {}\n",
    "    excluded_count = 0\n",
    "    \n",
    "    for d in dir_list:\n",
    "        txt_files = glob.glob(os.path.join(d, \"*.txt\"))\n",
    "        dir_file_count = 0\n",
    "        dir_name = os.path.basename(os.path.dirname(d))\n",
    "        \n",
    "        for fpath in txt_files:\n",
    "            filename = os.path.basename(fpath)\n",
    "            if filename in exclude_files:\n",
    "                excluded_count += 1\n",
    "                continue\n",
    "                \n",
    "            with open(fpath, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                content = file.read()\n",
    "                texts.append(content)\n",
    "                dir_file_count += 1\n",
    "        \n",
    "        total_files += dir_file_count\n",
    "        file_counts_by_dir[dir_name] = dir_file_count\n",
    "    \n",
    "    return texts, total_files, file_counts_by_dir, excluded_count\n",
    "\n",
    "\n",
    "\n",
    "# Read raw texts from specified directories\n",
    "raw_texts, total_text_count, files_per_dir, excluded_count = read_text_files_from_directories(\n",
    "    directories, files_to_exclude)\n",
    "\n",
    "# Calculate the word count for each text\n",
    "word_counts = [len(text.split()) for text in raw_texts]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total number of texts processed: {total_text_count}\")\n",
    "print(f\"Number of texts excluded: {excluded_count}\")\n",
    "print(\"\\nNumber of texts by directory:\")\n",
    "for dir_name, count in files_per_dir.items():\n",
    "    print(f\"{dir_name}: {count} texts\")\n",
    "\n",
    "# Calculate the average word count\n",
    "if word_counts:\n",
    "    average_word_count = sum(word_counts) / len(word_counts)\n",
    "    print(f\"\\nAverage Word Count: {average_word_count:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo texts found in the specified directories.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
